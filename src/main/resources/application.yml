server:
  port: 8080

spring:
  # 数据源配置
  datasource:
    # mysql8.0驱动要带cj 5.0不带cj
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://192.168.134.11:3306/my_db?useUnicode=true&characterEncoding=UTF-8&serverTimeZone=Asia/Shanghai
    username: root
    password: lfx@mysql666
    # 号称最快的连接池 默认
    hikari:
      # 连接池名
      pool-name: DateHikariCP
      # 最小空闲连接数
      minimum-idle: 5
      # 空闲连接最大存活时间 默认10分钟 600000 ms
      idle-timeout: 1800000
      # 最大连接数 默认10
      maximum-pool-size: 10
      # 从连接池返回的连接自动提交
      auto-commit: true
      # 连接最大存活时间，0表示永久存活 默认30分钟 1800000ms
      max-lifetime: 1800000
      # 连接超时时间，默认30秒 30000ms
      connection-timeout: 30000
      # 心跳机制 测试连接是否可用的查询语句
      connection-test-query: SELECT 1
  http:
    encoding: utf-8

  # Kafka 配置项，对应 KafkaProperties 配置类
  kafka:
    bootstrap-servers: 192.168.134.11:9091,192.168.134.11:9092,192.168.134.11:9093
    producer:
      acks: 1 # 0-不应答。1-leader 应答。all-所有 leader 和 follower 应答。
      retries: 0 # 发送失败时，重试发送的次数
      batch-size: 16384
      buffer-memory: 33554432
      key-serializer: org.apache.kafka.common.serialization.StringSerializer # 消息的 key 的序列化
      # value-serializer: org.apache.kafka.common.serialization.StringSerializer # 消息的 key 的序列化
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer # 消息的 value 的序列化
      # value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer # 消息的 value 的序列化
      properties:
        max.request.size: 3000000

    consumer:
      client-id: my-consumer
      group-id: my-group
      auto-offset-reset: earliest # 设置消费者分组最初的消费进度为 earliest
      enable-auto-commit: false
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      # value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
      properties:
        log.retention.ms: 1
        log.cleanup.cleanup: delete
        spring:
          json:
            trusted:
              packages: '*'
    listener:
      concurrency: 1
      ack-mode: MANUAL
      # 消费监听接口监听的主题不存在时，默认会报错。所以通过设置为 false ，解决报错
      missing-topics-fatal: false

  influx:
    bucket: my_db
    org: hhu
    token: E_QmZ4kURzSvQcVYxrIc5o_m5eUrwLCiSjftRqYtCD9pSXLcWisyV2oc30HK0tgFzqyJRLn7cq4M5E9hQdaU8g==
    url: http://192.168.134.11:8086
  # redis集群
  redis:
    host: 192.168.134.11
    port: 6379
    password: redis666
    # 默认操作的数据库
    database: 0
    # 超时时间
    timeout: 20000
    lettuce:
      pool:
        # 最大链接数
        max-active: 30
        # 最大空闲连接数
        max-idle: 30
        # 最小空闲连接数
        min-idle: 0
        # 最大链接阻塞等待时间 默认-1
        max-wait: 10000ms

kafka:
  topic:
    my-topic: my-topic

logging:
  # file:
    # name: A:\\kafka-learning\\file.log
  level:
    org:
      springframework:
        kafka: ERROR # spring-kafka
      apache:
        kafka: ERROR # kafka
